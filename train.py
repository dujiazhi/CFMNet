"""
This is the training demo of CFMNet for denoising images corrupted by AWGN.
To run the code, you should install pytorch first. 
By default, the training starts with a learning rate equal to 1e-3.
The training data are generated by "prepare_data", train_gray.h5, val_gray.h5


"Flexible Image Denoising with Multi-layer Conditional Feature Modulation "

If you have any question, please feel free to contact with me.
Jiazhi Du (e-mail: dujiazhi888@foxmail.com)

"""

import os
import sys
import cv2
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.utils as utils
from tensorboardX import SummaryWriter
from dataset import Dataset
import models
from utils import weights_init_kaiming, batch_psnr, batch_ssim, init_logger

if 'CUDA_DEVICE_ORDER' not in os.environ:
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
if 'CUDA_VISIBLE_DEVICES' not in os.environ:
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# torch.set_num_threads(2)

def main(args):

	# Load dataset
	print('> Loading dataset ...')
	dataset_train = Dataset(args.train_set,  shuffle=False, close_everytime=False)
	dataset_val = Dataset(args.val_set,  shuffle=False, close_everytime=False)
	loader_train = DataLoader(dataset=dataset_train, num_workers=0, \
							   batch_size=args.batch_size, shuffle=True,pin_memory=True,timeout=0)
	print("\t# of training samples: %d\n" % int(len(dataset_train)))

	# Init loggers
	if not os.path.exists(args.log_dir):
		os.makedirs(args.log_dir)
	writer = SummaryWriter(args.log_dir)
	logger = init_logger(args)
	# Create model
	if not args.gray:
		in_ch = 3
	else:
		in_ch = 1

	net = model.CFMNet(in_ch, in_ch, args.n_block)

	savename=''
	net.apply(weights_init_kaiming)
	# Define loss
	mseloss = nn.MSELoss(reduction='sum')
	# criterion = nn.MSELoss(size_average=True)
	# Move to GPU
	device_ids = [0]
	model = nn.DataParallel(net, device_ids=device_ids).cuda()
	#a=torch.load('net.pth')
	#model.load_state_dict(a)
	mseloss.cuda()
  	# Optimizer
	optimizer = optim.Adam(model.parameters(), lr=args.lr)

	# Resume training or start anew
	if args.resume_training:
		resumef = os.path.join(args.log_dir, 'ckpt.pth')
		if os.path.isfile(resumef):
			checkpoint = torch.load(resumef)
			print("> Resuming previous training")
			model.load_state_dict(checkpoint['state_dict'])
			optimizer.load_state_dict(checkpoint['optimizer'])

			training_params = checkpoint['training_params']
			start_epoch = training_params['start_epoch']

			print("=> loaded checkpoint '{}' (epoch {})"\
				  .format(resumef, start_epoch))
			print("=> loaded parameters :")
			print("==> checkpoint['optimizer']['param_groups']")
			print("\t{}".format(checkpoint['optimizer']['param_groups']))
			print("==> checkpoint['training_params']")
			for k in checkpoint['training_params']:
				print("\t{}, {}".format(k, checkpoint['training_params'][k]))
			argpri = vars(checkpoint['args'])
			print("==> checkpoint['args']")
			for k in argpri:
				print("\t{}, {}".format(k, argpri[k]))

			args.resume_training = False
		else:
			raise Exception("Couldn't resume training with checkpoint {}".\
				   format(resumef))
	else:
		start_epoch = 0
		training_params = {}
		training_params['step'] = 0
		training_params['current_lr'] = 0
	# Training
	
	for epoch in range(start_epoch, args.epochs):

		# Learning rate value scheduling according to args.milestone
		if epoch > args.milestone[2]:
			current_lr = args.lr / 1000.
		elif epoch > args.milestone[1]:
			current_lr = args.lr / 100.
		elif epoch > args.milestone[0]:
			current_lr = args.lr / 10.
		else:
			current_lr = args.lr

		# set learning rate in optimizer
		for param_group in optimizer.param_groups:
			param_group["lr"] = current_lr
		print('learning rate %f' % current_lr)
		# train
		for i, data in enumerate(loader_train, 0):
			# Pre-training step
			model.train()
			model.zero_grad()
			optimizer.zero_grad()
			# inputs: noise and noisy image
			img_train = data
			noise = torch.zeros(img_train.size())
			stdn = np.random.uniform(args.noiseIntL[0], args.noiseIntL[1],size=noise.size()[0])

			for nx in range(noise.size()[0]):
				sizen = noise[0, :, :, :].size()
				noise[nx, :, :, :] = torch.FloatTensor(sizen).\
									normal_(mean=0, std=stdn[nx])
			imgn_train = img_train + noise
			# Create input
			img_train = img_train.cuda()
			noise = noise.cuda()
			imgn_train = imgn_train.cuda()
			stdn_var = torch.tensor(stdn,dtype=torch.float32).cuda()
			out_train = model(imgn_train, stdn_var)

			loss = mseloss(out_train, img_train) / (imgn_train.size()[0]*2)

			loss.backward()
			optimizer.step()

			# Results
			model.eval()
			with torch.no_grad():
				out_train = torch.clamp(model(imgn_train, stdn_var), 0., 1.)

			psnr_train = batch_psnr(out_train, img_train, 1.)

			if training_params['step'] % args.save_every == 0:
				# Log the scalar values
				writer.add_scalar('loss', loss.item(), training_params['step'],walltime=training_params['step'])
				writer.add_scalar('PSNR on training data', psnr_train,training_params['step'],walltime=training_params['step'])
				print("[epoch %d][%d/%d] loss: %.4f PSNR_train: %.4f" %\
					(epoch+1, i+1, len(loader_train), loss.item(), psnr_train))
			training_params['step'] += 1
			# break
		# The end of each epoch
		model.eval()
		# Validation
		with torch.no_grad():
			psnr_val = 0
			ssim_val=0
			for valimg in dataset_val:
				img_val = torch.unsqueeze(valimg, 0)
				noise = torch.FloatTensor(img_val.size()).normal_(mean=0, std=args.val_noiseL)
				imgn_val = img_val + noise
				img_val, imgn_val = torch.tensor(img_val).cuda(), torch.tensor(imgn_val).cuda()
				sigma_noise = torch.tensor([args.val_noiseL]).cuda()
				out_val = torch.clamp(model(imgn_val, sigma_noise), 0., 1.)
				psnr_val += batch_psnr(out_val, img_val, 1.)
				ssim_val += batch_ssim(out_val, img_val, 1.)

			psnr_val /= len(dataset_val)
			ssim_val /= len(dataset_val)
			print("\n[epoch %d] PSNR_val: %.4f" % (epoch+1, psnr_val))
			print("\n[epoch %d] ssim_val: %.4f" % (epoch + 1, ssim_val))
			writer.add_scalar('PSNR on validation data', psnr_val, epoch, walltime=epoch)
			writer.add_scalar('ssim on validation data', ssim_val, epoch, walltime=epoch)
			writer.add_scalar('Learning rate', current_lr, epoch,walltime=epoch)
		# Log val images
		try:
			imclean = utils.make_grid([img_val.data[0]].clamp(0., 1.), \
											nrow=1, normalize=False)
			imnsy = utils.make_grid([imgn_val.data[0],].clamp(0., 1.), \
											nrow=1, normalize=False)
			writer.add_image('Clean validation image ', imclean, epoch,walltime=epoch)
			writer.add_image('Noisy validation image ', imnsy, epoch,walltime=epoch)

			imrecons = utils.make_grid(out_val.data[0].clamp(0., 1.), \
											nrow=1, normalize=False)
			writer.add_image('Reconstructed validation image', \
								imrecons, epoch)
			# Log training images
		except Exception as e:
			logger.error("Couldn't log results: {}".format(e))

		# save model and checkpoint
		training_params['start_epoch'] = epoch + 1
		torch.save(model.state_dict(), os.path.join(args.log_dir, savename+'net.pth'))
		save_dict = { \
			'state_dict': model.state_dict(), \
			'optimizer' : optimizer.state_dict(), \
			'training_params': training_params, \
			'args': args\
			}
		torch.save(save_dict, os.path.join(args.log_dir, 'ckpt.pth'))
		if training_params['start_epoch'] > 0:
			if epoch % args.save_every_epochs == 0:
				torch.save(model.state_dict(), os.path.join(args.log_dir, savename + 'ckpt_e{}.pth'.format(epoch)))
		del save_dict

if __name__ == "__main__":

	parser = argparse.ArgumentParser(description="CFMNet")
	parser.add_argument("--gray", action='store_true',default=True,\
						help='train grayscale image denoising instead of RGB')

	parser.add_argument("--log_dir", type=str, default="logs", \
					 help='path of log files')
	parser.add_argument("--train_set", type=str, default="./train_gray.h5", help="path to trian set")
	parser.add_argument("--val_set", type=str, default="./val_gray.h5", help="path to val set")
	#Training parameters
	parser.add_argument("--n_block", type=int, default=2, 	\
					 help="the number of blocks")
	parser.add_argument("--batch_size", type=int, default=64, 	\
					 help="Training batch size")
	parser.add_argument("--epochs", "--e", type=int, default=90, \
					 help="Number of total training epochs")
	parser.add_argument("--resume_training", "--r", action='store_true',\
						help="resume training from a previous checkpoint")
	parser.add_argument("--milestone", nargs=2, type=int, default=[50,70,80], \
			 			help="When to decay learning rate; should be lower than 'epochs'")
	parser.add_argument("--lr", type=float, default=1e-4, \
					 help="Initial learning rate")
	parser.add_argument("--save_every", type=int, default=10,\
						help="Number of training steps to log psnr and perform \
						orthogonalization")
	parser.add_argument("--save_every_epochs", type=int, default=1,\
						help="Number of training epochs to save state")
	parser.add_argument("--noiseIntL", nargs=2, type=int, default=[0, 75], \
					 help="Noise training interval")
	parser.add_argument("--val_noiseL", type=float, default=25, \
						help='noise level used on validation set')
	argspar = parser.parse_args()
	# Normalize noise between [0, 1]
	argspar.val_noiseL /= 255.
	argspar.noiseIntL[0] /= 255.
	argspar.noiseIntL[1] /= 255.

	print("\n### Training CFMNet model ###")
	print("> Parameters:")
	for p, v in zip(argspar.__dict__.keys(), argspar.__dict__.values()):
		print('\t{}: {}'.format(p, v))
	print('\n')

	main(argspar)